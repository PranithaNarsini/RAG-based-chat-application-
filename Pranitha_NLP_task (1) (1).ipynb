{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the necessary libraries langchain,openAI,chromadb.\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldjUVj1cTY5f",
        "outputId": "aee241dc-c9cd-4b7f-ea25-a4b4331afe2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.251-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.18-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.251 langsmith-0.0.18 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.5-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.28 (from chromadb)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.12)\n",
            "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
            "  Downloading chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.7.1)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.0)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (1.26.16)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.6)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.2)\n",
            "Building wheels for collected packages: chroma-hnswlib, pypika\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.2-cp310-cp310-linux_x86_64.whl size=2287468 sha256=cdd69530176bdf36959308373987bacbac3c68b6227be5869743885d461c4ae1\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/2b/0d/ee457f6782f75315bb5828d5c2dc5639d471afbd44a830b9dc\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=dc0cf8a489ab209426436b0a16b90cb59cf700168bad733c7d46b45d71d06419\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built chroma-hnswlib pypika\n",
            "Installing collected packages: tokenizers, pypika, monotonic, websockets, uvloop, requests, python-dotenv, pulsar-client, overrides, humanfriendly, httptools, h11, chroma-hnswlib, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 chroma-hnswlib-0.7.2 chromadb-0.4.5 coloredlogs-15.0.1 fastapi-0.99.1 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.15.1 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 pypika-0.48.9 python-dotenv-1.0.0 requests-2.31.0 starlette-0.27.0 tokenizers-0.13.3 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "1PcrKBotSlM_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P_CRtBtoTGj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kHXfGbkTHwu",
        "outputId": "cee11e45-3f92-4db3-dcd7-dc77878b7678"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules for text summarization, document loading, OpenAI integration, and file searching.\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import OpenAI, PromptTemplate\n",
        "import glob"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T11:11:29.756130Z",
          "iopub.execute_input": "2023-08-03T11:11:29.756652Z",
          "iopub.status.idle": "2023-08-03T11:11:33.238566Z",
          "shell.execute_reply.started": "2023-08-03T11:11:29.756611Z",
          "shell.execute_reply": "2023-08-03T11:11:33.237316Z"
        },
        "trusted": true,
        "id": "GcTGEX92SYub"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set OpenAI API key, initialize OpenAI model, and summarize PDF files from a folder using Langchain.\n",
        "import os\n",
        "\n",
        "#os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "#set OPENAI_API_KEY=Your_Private_Openai_Key\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "#os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
        "\n",
        "llm = OpenAI(temperature=0.2)\n",
        "\n",
        "#export OPENAI_API_KEY={Your_Private_Openai_Key}\n",
        "def summarize_pdfs_from_folder(pdfs_folder):\n",
        "    summaries = []\n",
        "    for pdf_file in glob.glob(pdfs_folder + \"/*.pdf\"):\n",
        "        loader = PyPDFLoader(pdf_file)\n",
        "        docs = loader.load_and_split()\n",
        "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "        summary = chain.run(docs)\n",
        "        print(\"Summary for: \", pdf_file)\n",
        "        print(summary)\n",
        "        print(\"\\n\")\n",
        "        summaries.append(summary)\n",
        "\n",
        "    return summaries"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T15:14:33.197922Z",
          "iopub.execute_input": "2023-08-03T15:14:33.198405Z",
          "iopub.status.idle": "2023-08-03T15:14:33.209326Z",
          "shell.execute_reply.started": "2023-08-03T15:14:33.198369Z",
          "shell.execute_reply": "2023-08-03T15:14:33.207904Z"
        },
        "trusted": true,
        "id": "82GL3Bw5SYuc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate custom summaries for PDF files from a folder using provided prompts and Langchain.\n",
        "def custom_summary(pdf_folder, custom_prompt):\n",
        "    summaries = []\n",
        "    for pdf_file in glob.glob(pdf_folder + \"/*.pdf\"):\n",
        "        loader = PyPDFLoader(pdf_file)\n",
        "        docs = loader.load_and_split()\n",
        "        prompt_template = custom_prompt + \"\"\"\n",
        "\n",
        "        {text}\n",
        "\n",
        "        SUMMARY:\"\"\"\n",
        "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\",\n",
        "                                    map_prompt=PROMPT, combine_prompt=PROMPT)\n",
        "        summary_output = chain({\"input_documents\": docs},return_only_outputs=True)[\"output_text\"]\n",
        "        summaries.append(summary_output)\n",
        "\n",
        "    return summaries"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T12:45:44.814150Z",
          "iopub.execute_input": "2023-08-03T12:45:44.814697Z",
          "iopub.status.idle": "2023-08-03T12:45:44.823327Z",
          "shell.execute_reply.started": "2023-08-03T12:45:44.814655Z",
          "shell.execute_reply": "2023-08-03T12:45:44.822072Z"
        },
        "trusted": true,
        "id": "rKG2AbR8SYud"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the input folder \"pranitha\".\n",
        "pathfolder=\"/content/drive/MyDrive/pranitha\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T12:48:46.999340Z",
          "iopub.execute_input": "2023-08-03T12:48:47.000115Z",
          "iopub.status.idle": "2023-08-03T12:48:47.007769Z",
          "shell.execute_reply.started": "2023-08-03T12:48:47.000068Z",
          "shell.execute_reply": "2023-08-03T12:48:47.006022Z"
        },
        "trusted": true,
        "id": "SirM3yRYSYue"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEeYtCNfUWVr",
        "outputId": "c983ab61-1bc2-402b-8b25-63473c9155c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.14.0-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR5KMoJGUnvg",
        "outputId": "bafd5b90-4bf8-4c00-be2c-f38f998fbc9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate summaries for PDF files from the specified folder and store them in the 'summaries' variable.\n",
        "summaries = summarize_pdfs_from_folder(pathfolder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX8V--sFUQeb",
        "outputId": "cae2d4c9-ea25-4b47-83c0-677f873de836"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for:  /content/drive/MyDrive/pranitha/3397271.3401075.pdf\n",
            " This paper presents ColBERT, a novel ranking model that adapts deep language models such as BERT for efficient retrieval. It is two orders-of-magnitude faster than existing BERT-based models, while only minimally impacting re-ranking quality and outperforming non-BERT baselines. It can scale to end-to-end neural retrieval directly from a large document collection, improving recall over existing models. It references 21-39 different papers and articles that discuss various methods of re-ranking documents, as well as three other papers related to cross-domain modeling of sentence-level evidence for document retrieval.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for:  /content/drive/MyDrive/pranitha/2104.07186.pdf\n",
            " This paper presents a new retrieval model called COIL (Contextualized Inverted List) which uses BERT-based token encoding to pre-compute document representations and build a search index. It is compared to other deep language models such as DeepCT, DocT5Query, and ColBERT. Experiments are conducted on two large-scale ad hoc retrieval benchmarks from the TREC 2019 Deep Learning shared task and results show that COIL is more computationally efficient than the other models, significantly outperforming both lexical and dense systems in terms of MRR and NDCG. Additionally, reducing the CLS dimension and token dimension had very small performance difference.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for:  /content/drive/MyDrive/pranitha/2106.14807.pdf\n",
            " This paper presents a conceptual framework for understanding recent developments in information retrieval, which can be organized along two dimensions: sparse vs. dense representations and unsupervised vs. learned representations. It introduces a novel technique called \"uniCOIL\" which achieves the current state-of-the-art in sparse retrieval on the MS MARCO passage ranking dataset. Additionally, the paper discusses techniques such as DPR, ANCE, DeepCT, DeepImpact, and COIL in relation to their framework, and examines the trade-offs between output quality, time, and space in modern information retrieval techniques. It also discusses four studies related to dense passage retrieval for open-domain question answering.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for:  /content/drive/MyDrive/pranitha/2301.03266.pdf\n",
            " This paper discusses the use of Doc2Query, a query prediction technique, to improve the effectiveness of text ranking and retrieval. Experiments conducted on the MS MARCO dataset show that Doc2Query can improve retrieval effectiveness by up to 16%, while reducing the index size and computational costs. The paper reviews recent research on the topic, including MS MARCO, Passage Re-ranking with BERT, Document Expansion by Query Prediction, and more. It also mentions the TILDE: Term Independent Likelihood Model for Passage Re-Ranking.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for:  /content/drive/MyDrive/pranitha/2303.07678.pdf\n",
            " This paper discusses the use of Large Language Models (LLMs) to generate pseudo-documents for query-based retrieval tasks. Experiments show that query2doc, a query expansion approach, improves the performance of BM25 by 3-15% on ad-hoc IR datasets such as MS-MARCO and TREC DL. It also provides an overview of the hyperparameters used for training dense retrievers, the format of the prompts used for LLMs, and the ablation experiments conducted to evaluate the performance of the model.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = summarize_pdfs_from_folder(pathfolder)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:12:21.063087Z",
          "iopub.execute_input": "2023-08-03T14:12:21.065073Z",
          "iopub.status.idle": "2023-08-03T14:15:22.910404Z",
          "shell.execute_reply.started": "2023-08-03T14:12:21.065021Z",
          "shell.execute_reply": "2023-08-03T14:15:22.908512Z"
        },
        "trusted": true,
        "id": "qSRxLQP6SYuf",
        "outputId": "2a398d87-a405-473c-8b5a-cb1790e9e249"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Summary for:  /kaggle/input/pranitha/2301.03266.pdf\n\n\nThis paper explores the effectiveness of Doc2Query, a two-phase approach to document expansion, in improving the retrieval of documents. Experiments on the MS MARCO dataset show that filtering out the least relevant queries prior to indexing can improve the retrieval effectiveness by up to 16%, reduce query execution time by 23%, and reduce the index size by 33%. Additionally, the paper covers a range of topics related to information retrieval, such as passage re-ranking with BERT, document expansion by query prediction, and efficient open-domain question answering.\n\n\nSummary for:  /kaggle/input/pranitha/2104.07186.pdf\n This paper introduces a new retrieval system, COIL, which uses contextualized term similarities to improve lexical retrieval performance. It uses an inverted list indexing to efficiently traverse the subset of documents in query terms' inverted lists and a Transformer language model to encode query and document tokens into contextualized vector representations. Experiments on two large-scale ad hoc retrieval benchmarks show that COIL significantly outperforms both lexical and dense systems in MRR and NDCG, and retains a small advantage in recall. It also demonstrates that exact lexical match can capture complicated matching patterns.\n\n\nSummary for:  /kaggle/input/pranitha/2106.14807.pdf\n This paper presents a conceptual framework for understanding recent developments in information retrieval, including sparse vs. dense representations and unsupervised vs. learned representations. It introduces a novel technique called \"uniCOIL\" and examines techniques such as DPR, ANCE, DeepCT, DeepImpact, and COIL. It also explores hybrid combinations of dense and sparse retrieval techniques, and provides insight into potential ablation experiments. Results show that no clear winner has emerged yet, and that hybrid approaches appear to be more effective than either dense or sparse representations alone.\n\n\nSummary for:  /kaggle/input/pranitha/2303.07678.pdf\n This paper presents a query expansion approach, called query2doc, which uses large language models (LLMs) to generate pseudo-documents to expand queries. Experiments show that query2doc improves the performance of BM25 by 3-15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, and also benefits state-of-the-art dense retrievers. Furthermore, the method also shows good performance in zero-shot out-of-domain settings. Additionally, the paper discusses various methods for open-domain question answering, such as Dense Passage Retrieval, Relevance-Based Language Models, DeepImpact, Coil, Pyserini, Query Language Models, WordNet, Doc2Query, Document Expansion by Query Prediction, RocketQA, RocketQAv2, Recitation-Augmented Language Models, Beir Benchmark, Llama Open Foundation Language Models, Trec-Covid, Fact or Fiction, and Simlm Pre-Training.\n\n\nSummary for:  /kaggle/input/pranitha/3397271.3401075.pdf\n This paper presents ColBERT, a novel ranking model that adapts deep language models (LMs) such as BERT for efficient retrieval. It is evaluated on MS MARCO Ranking and TREC CAR datasets, and compared to existing neural matching models such as KNRM, Duet, ConvKNRM, and fastText+ConvKNRM. Results show that ColBERT is two orders-of-magnitude faster than existing BERT-based models, while only minimally impacting re-ranking quality and outperforming non-BERT baselines. The paper also references 20+ research papers that explore topics such as optimizing exact maximum inner product search, context-aware sentence/passage term importance estimation for first stage retrieval, and cross-domain modeling of sentence-level evidence for document retrieval.\n\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate custom summaries for PDF files using the provided prompt, save them in a text file named \"custom_summaries.txt\".\n",
        "CUSTOM_PROMPT = \"Write a concise summary of the following paper with this structure: Problem being solved; Approach; Main results; Main Discussion Points\"\n",
        "custom_summaries = custom_summary(pathfolder, custom_prompt=CUSTOM_PROMPT)\n",
        "# # Save all summaries into one .txt file\n",
        "with open(\"custom_summaries.txt\", \"w\") as f:\n",
        "    for summary in custom_summaries:\n",
        "        f.write(summary + \"\\n\"*3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLBGrZTyiJ-t",
        "outputId": "8ce8666d-0608-46fe-e53d-06cad0c01b0b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-VbLX0Xtl91yg6UDDsqOKnDqy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOw99Dt6i6an",
        "outputId": "73a76b3b-454e-48f1-a6e1-57b16d3ef8d7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' This paper presents ColBERT, a novel ranking model that adapts deep language models (LMs) for efficient retrieval. It introduces a late interaction architecture that independently encodes the query and the document using BERT, and then employs a cheap yet powerful interaction step that models their fine-grained similarity. Results show that ColBERT is competitive with existing BERT-based models, while executing two orders-of-magnitude faster and requiring up to four orders-of-magnitude fewer FLOPs per query. The main discussion points are the effectiveness of ColBERT in comparison to existing BERT-based models, and its ability to pre-compute document representations offline, considerably speeding up query processing.',\n",
              " ' This paper presents COIL, a contextualized exact match retrieval architecture that brings semantic lexical matching. It processes documents with deep LM offline and produces representations for each document token, which are then grouped by their surface tokens into inverted lists. At search time, vector similarities between query-document overlapping term contextualized representations are used to compute matching scores. Results demonstrate that COIL significantly outperforms classical and deep LM augmented lexical retrievers as well as state-of-the-art dense retrievers on two retrieval tasks. The main discussion points include the comparison of COIL to existing retrieval models, the advantages of COIL, and the potential for future work.',\n",
              " ' This paper presents a conceptual framework for understanding recent developments in information retrieval, which can be organized into two pairs of contrasts: sparse vs. dense representations and unsupervised vs. learned representations. It is used to analyze techniques such as DPR, ANCE, DeepCT, DeepImpact, and COIL. A novel technique called uniCOIL is proposed, which achieves the current state-of-the-art in sparse retrieval on the MS MARCO passage ranking dataset. The main discussion points are the relationship between the techniques, the gaps revealed by the analysis, and the implementation of uniCOIL.',\n",
              " ' This paper presents Doc2Query, a novel approach to query expansion that uses a pretrained sequence-to-sequence model to generate queries from documents. Experiments on a variety of datasets show that Doc2Query outperforms existing methods. The authors discuss the advantages of their approach, such as its ability to generate more relevant queries and its scalability, as well as potential applications in question answering and conversational search.',\n",
              " ' This paper explores the use of the Gibbs (1988) Reflective Cycle as a framework for reflective practice in nursing. The paper outlines the six stages of the cycle and discusses the importance of reflective practice in nursing. The results show that the Gibbs (1988) Reflective Cycle is an effective framework for reflective practice in nursing. The paper also discusses the importance of reflective practice in nursing and the advantages of using the Gibbs (1988) Reflective Cycle as a framework.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all summaries into one .txt file\n",
        "with open(\"summaries.txt\", \"w\") as f:\n",
        "    for summary in summaries:\n",
        "        f.write(summary + \"\\n\"*3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:26:35.444085Z",
          "iopub.execute_input": "2023-08-03T14:26:35.444531Z",
          "iopub.status.idle": "2023-08-03T14:26:35.452097Z",
          "shell.execute_reply.started": "2023-08-03T14:26:35.444489Z",
          "shell.execute_reply": "2023-08-03T14:26:35.450841Z"
        },
        "trusted": true,
        "id": "kcmbFUOMSYui"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying Multiple PDFS"
      ],
      "metadata": {
        "id": "FXwhG3nRSYuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# .py\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:26:46.271862Z",
          "iopub.execute_input": "2023-08-03T14:26:46.272283Z",
          "iopub.status.idle": "2023-08-03T14:26:46.286835Z",
          "shell.execute_reply.started": "2023-08-03T14:26:46.272251Z",
          "shell.execute_reply": "2023-08-03T14:26:46.285533Z"
        },
        "trusted": true,
        "id": "YgFkiCEESYum"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "!pip install fitz\n",
        "#pip install PyMuPDF\n",
        "!pip3 install PyMuPDF Pillow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:26:50.893212Z",
          "iopub.execute_input": "2023-08-03T14:26:50.893992Z",
          "iopub.status.idle": "2023-08-03T14:27:50.515143Z",
          "shell.execute_reply.started": "2023-08-03T14:26:50.893949Z",
          "shell.execute_reply": "2023-08-03T14:27:50.513444Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AOi01EPLSYum",
        "outputId": "9925c9e9-75cf-4a94-f231-0bf84f21d9f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-6.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.21.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (4.0.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.8.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (1.5.3)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.1.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (67.7.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.6)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.1)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.0-py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.19.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traits!=5.0,<6.4,>=4.6 (from nipype->fitz)\n",
            "  Downloading traits-6.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.12.2)\n",
            "Collecting etelemetry>=0.2.0 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting looseversion (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2022.7.1)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (0.18.3)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.3)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.2.0->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2023.7.22)\n",
            "Installing collected packages: looseversion, traits, simplejson, isodate, configparser, configobj, ci-info, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed ci-info-0.3.0 configobj-5.0.8 configparser-6.0.0 etelemetry-0.3.0 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.8.6 prov-2.0.0 pyxnat-1.6 rdflib-7.0.0 simplejson-3.19.1 traits-6.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.22.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Installing collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.22.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images"
      ],
      "metadata": {
        "id": "PF05D5X2fAUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract images from a PDF file using PyMuPDF (fitz) and save them as PNGs, with specified output settings.\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Output directory for the extracted images\n",
        "output_dir = \"extracted_images\"\n",
        "# Desired output image format\n",
        "output_format = \"png\"\n",
        "# Minimum width and height for extracted images\n",
        "min_width = 1\n",
        "min_height = 1\n",
        "# Create the output directory if it does not exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "# file path you want to extract images from\n",
        "file = \"/content/drive/MyDrive/pranitha/3397271.3401075.pdf\"\n",
        "# open the file\n",
        "pdf_file = fitz.open(file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:26:30.188402Z",
          "iopub.execute_input": "2023-08-03T14:26:30.188875Z",
          "iopub.status.idle": "2023-08-03T14:26:30.208974Z",
          "shell.execute_reply.started": "2023-08-03T14:26:30.188840Z",
          "shell.execute_reply": "2023-08-03T14:26:30.207726Z"
        },
        "trusted": true,
        "id": "FUYYquTbSYun"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over PDF pages, extract images, check dimensions, and save them if size requirements are met.\n",
        "# Iterate over PDF pages\n",
        "for page_index in range(len(pdf_file)):\n",
        "    # Get the page itself\n",
        "    page = pdf_file[page_index]\n",
        "    # Get image list\n",
        "    image_list = page.get_images(full=True)\n",
        "    # Print the number of images found on this page\n",
        "    if image_list:\n",
        "        print(f\"[+] Found a total of {len(image_list)} images in page {page_index}\")\n",
        "    else:\n",
        "        print(f\"[!] No images found on page {page_index}\")\n",
        "    # Iterate over the images on the page\n",
        "    for image_index, img in enumerate(image_list, start=1):\n",
        "        # Get the XREF of the image\n",
        "        xref = img[0]\n",
        "        # Extract the image bytes\n",
        "        base_image = pdf_file.extract_image(xref)\n",
        "        image_bytes = base_image[\"image\"]\n",
        "        # Get the image extension\n",
        "        image_ext = base_image[\"ext\"]\n",
        "        # Load it to PIL\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        # Check if the image meets the minimum dimensions and save it\n",
        "        if image.width >= min_width and image.height >= min_height:\n",
        "            image.save(\n",
        "                open(os.path.join(output_dir, f\"image{page_index + 1}_{image_index}.{output_format}\"), \"wb\"),\n",
        "                format=output_format.upper())\n",
        "        else:\n",
        "            print(f\"[-] Skipping image {image_index} on page {page_index} due to its small size.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KeyQ8vydJm7",
        "outputId": "e0de39a4-2d35-49e9-cc79-dc5029d931e2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Found a total of 2 images in page 0\n",
            "[+] Found a total of 14 images in page 1\n",
            "[+] Found a total of 3 images in page 2\n",
            "[!] No images found on page 3\n",
            "[!] No images found on page 4\n",
            "[!] No images found on page 5\n",
            "[!] No images found on page 6\n",
            "[!] No images found on page 7\n",
            "[!] No images found on page 8\n",
            "[!] No images found on page 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer\n",
        "!pip install unstructured\n",
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qSu_StbgWR1C",
        "outputId": "653e705a-8860-4d6b-e0de-b5821c46ffa1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer\n",
            "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome (from pdfminer)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pdfminer\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140095 sha256=8f2e815d9638dfd8f96a2487342ae0edd88d328ee9e749805eba4005c524fcb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/c1/68/f7bd0a8f514661f76b5cbe3b5f76e0033d79f1296012cbbf72\n",
            "Successfully built pdfminer\n",
            "Installing collected packages: pycryptodome, pdfminer\n",
            "Successfully installed pdfminer-20191125 pycryptodome-3.18.0\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.7.22)\n",
            "Installing collected packages: filetype, python-magic, unstructured\n",
            "Successfully installed filetype-1.2.0 python-magic-0.4.27 unstructured-0.9.0\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six)\n",
            "  Downloading cryptography-41.0.3-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "Successfully installed cryptography-41.0.3 pdfminer.six-20221105\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cryptography"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract image file names from a directory, load images using a custom loader, and create a dictionary with filenames as keys and loaded images as values.\n",
        "pathimage=\"/content/extracted_images\"\n",
        "dt2=[]\n",
        "\n",
        "# import OS module\n",
        "import os\n",
        "\n",
        "# Get the list of all files and directories\n",
        "dir_list = os.listdir(pathimage)\n",
        "\n",
        "# prints all files\n",
        "print(dir_list)\n",
        "\n",
        "for i in dir_list:\n",
        "    dt2.append(i)\n",
        "dict_dt={}\n",
        "for t12 in dir_list:\n",
        "    from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "    path2=pathimage+\"/\"\n",
        "    loader = UnstructuredImageLoader(path2+t12)\n",
        "    imagedt = loader.load()\n",
        "    dict_dt[t12]=imagedt\n",
        "\n",
        "for x in dict_dt:\n",
        "  print(dict_dt[x])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:25:37.871452Z",
          "iopub.execute_input": "2023-08-03T14:25:37.871955Z",
          "iopub.status.idle": "2023-08-03T14:25:42.109709Z",
          "shell.execute_reply.started": "2023-08-03T14:25:37.871919Z",
          "shell.execute_reply": "2023-08-03T14:25:42.107915Z"
        },
        "trusted": true,
        "id": "LsDDM57ASYup",
        "outputId": "4607755a-66a2-4892-ec37-bc93631fd0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['image3_3.png', 'image3_1.png', 'image2_13.png', 'image2_9.png', 'image1_1.png', 'image2_4.png', 'image2_12.png', 'image2_3.png', 'image2_5.png', 'image2_1.png', 'image2_14.png', 'image2_7.png', 'image2_2.png', 'image1_2.png', 'image2_11.png', 'image2_10.png', 'image2_6.png', 'image2_8.png', 'image3_2.png']\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image3_3.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image3_1.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_13.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_9.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image1_1.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_4.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_12.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_3.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_5.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_1.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_14.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_7.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_2.png'})]\n[Document(page_content='®\\n\\nCheck for\\n\\nupdates', metadata={'source': '/kaggle/working/extracted_images/image1_2.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_11.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_10.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_6.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image2_8.png'})]\n[Document(page_content='', metadata={'source': '/kaggle/working/extracted_images/image3_2.png'})]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfVUy0qneFvw",
        "outputId": "d41d45b1-1ed4-4c74-a6cf-df9a26536f47"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF documents from a directory using PyPDFDirectoryLoader, create a vector store index using VectorstoreIndexCreator.\n",
        "loader = PyPDFDirectoryLoader(pathfolder)\n",
        "\n",
        "\n",
        "#loader2 = PyPDFLoader(\"/kaggle/input/pranitha/2303.07678.pdf\")\n",
        "#loader=loader2+dt2\n",
        "doc = loader.load()\n",
        "\n",
        "\n",
        "# Create the vector store index\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T15:15:47.118149Z",
          "iopub.execute_input": "2023-08-03T15:15:47.118607Z",
          "iopub.status.idle": "2023-08-03T15:15:58.064918Z",
          "shell.execute_reply.started": "2023-08-03T15:15:47.118557Z",
          "shell.execute_reply": "2023-08-03T15:15:58.063416Z"
        },
        "trusted": true,
        "id": "gc02RJJRSYuq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"overview of Figure 2: MRR on MS-MARCO dev set w.r.t the per\u0002centage of labeled data used for fine-tuninng with dpr w/o quer2doc , dpr w query2doc?\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:28:03.250585Z",
          "iopub.execute_input": "2023-08-03T14:28:03.251031Z",
          "iopub.status.idle": "2023-08-03T14:28:25.306490Z",
          "shell.execute_reply.started": "2023-08-03T14:28:03.250997Z",
          "shell.execute_reply": "2023-08-03T14:28:25.304802Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w3zqyuVYSYuq",
        "outputId": "6c31efb8-3ec2-4d5a-d1a4-f4bc75adda02"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The results show that the “DPR + query2doc” variant consistently outperforms the DPR baseline by approximately 1%, regardless of the amount of data used for fine-tuning.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1=\"what is the value of MRR ondev set when 50% of labeled data for fine tuning in dpr w/o query2doc ?\"\n",
        "index.query(t1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T15:15:59.272411Z",
          "iopub.execute_input": "2023-08-03T15:15:59.272844Z",
          "iopub.status.idle": "2023-08-03T15:16:20.507248Z",
          "shell.execute_reply.started": "2023-08-03T15:15:59.272811Z",
          "shell.execute_reply": "2023-08-03T15:16:20.505996Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BrfrygjKSYur",
        "outputId": "cab51b14-4a64-4e4a-9b76-43e451858120"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 32.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the central idea that can allow for scaling transformers to 1 million tokens?\"\n",
        "\n",
        "index.query(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T15:16:27.931104Z",
          "iopub.execute_input": "2023-08-03T15:16:27.931543Z",
          "iopub.status.idle": "2023-08-03T15:16:34.151700Z",
          "shell.execute_reply.started": "2023-08-03T15:16:27.931506Z",
          "shell.execute_reply": "2023-08-03T15:16:34.150359Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KPTVe8VDSYus",
        "outputId": "41adb654-4072-4c59-e0f4-6952a95ee675"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The central idea is to use dense representations and learned sparse representations, which allow for the model to choose a new basis derived from transformer representations. This allows the encoder to represent the \"meaning\" of texts in relatively small fixed-width vectors.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"breif me about table 4: Sample query document pairs with similarity scores produced by COIL.?\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T14:46:05.570455Z",
          "iopub.execute_input": "2023-08-03T14:46:05.572292Z",
          "iopub.status.idle": "2023-08-03T14:46:08.147269Z",
          "shell.execute_reply.started": "2023-08-03T14:46:05.572240Z",
          "shell.execute_reply": "2023-08-03T14:46:08.146301Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "G1RPkkdOSYut",
        "outputId": "207beac5-5364-4414-a2f4-0bc20408da20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Table 4 shows examples of how COIL differentiates different senses of a word under different contexts. It provides query-document vector similarities computed with vectors generated by COIL for different contexts. It demonstrates how COIL systems gain strength over lexical systems.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"summary for Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List \"\n",
        "index.query(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-03T15:26:39.546058Z",
          "iopub.execute_input": "2023-08-03T15:26:39.546596Z",
          "iopub.status.idle": "2023-08-03T15:26:40.789330Z",
          "shell.execute_reply.started": "2023-08-03T15:26:39.546553Z",
          "shell.execute_reply": "2023-08-03T15:26:40.788030Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "ffiu4WnISYut",
        "outputId": "ff3c746f-86af-44a5-8435-33c5cde73d44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This paper presents COIL, a contextualized exact match retrieval architecture that brings semantic lexical matching. COIL scoring is based on overlapping query document tokens' contextualized representations. The new architecture stores contextualized token representations in inverted lists, bringing together the efficiency of exact match and the representation power of deep language models. Experimental results show COIL outperforms classical lexical retrieval and state-of-the-art dense retrieval systems.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Give me the abstract about Query2doc: Query Expansion with Large Language Models?\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "JK3pmyZySYuu",
        "outputId": "7063343e-80b4-4a14-b10a-7336fece12e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what are the techniques used in Query2doc: Query Expansion with Large Language Models \"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "M7UTrKmxZady",
        "outputId": "6911e0cd-7026-41dc-d158-9b1ed9c3bdef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The techniques used in Query2doc: Query Expansion with Large Language Models are few-shot prompting large language models (LLMs), query disambiguation, and generating pseudo-documents.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"give me the conclusion of Query2doc: Query Expansion with Large Language Models? \"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "_HVFUBaUaBo6",
        "outputId": "d7785287-e004-4e7b-cdba-a331865cd611"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The conclusion of Query2doc: Query Expansion with Large Language Models is that the proposed method boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning, and also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"give me the overview analysis of  Query2doc: Query Expansion with Large Language Models? \"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "3B_xL1i5ae0w",
        "outputId": "a36d1be7-5246-410d-9a3e-59b59e80fdf9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Query2doc is a simple yet effective query expansion approach that uses large language models (LLMs) to generate pseudo-documents. These pseudo-documents contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results show that query2doc boosts the performance of BM25 by 3-15% on ad-hoc IR datasets without any model fine-tuning. It also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"give me the values of  w/ query only for TREC 19 and TREC 20 in table 4 from the Query2doc: Query Expansion with Large Language Models?\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "X4PeJNjjbE2z",
        "outputId": "8f3db67b-20ac-4494-a1d8-ad1cff85c71a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 51.2 and 47.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIlLM6UipV7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}